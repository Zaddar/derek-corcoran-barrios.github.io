---
title: "Automatización de selección de modelos, variables fijas y aleatorias e introducción a crossvalidation"
author: "Derek Corcoran"
date: "`r format(Sys.time(), '%d/%m, %Y')`"
output:
  ioslides_presentation:
    widescreen: true
    incremental: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, cache = F, tidy = TRUE, tidy.opts= list(blank = FALSE, width.cutoff = 80))
library(tidyverse)
library(caret)
library(MuMIn)
library(broom)
library(kableExtra)
library(glmnet)
options("kableExtra.html.bsTable" = T)
```

# Variables fijas vs aleatorias

## Variables fijas vs aleatorias

* Fijas (continuas o categóricas)
    + Se espera que tengan una influencia predecible y sistemática en sobre lo que queremos explicar. Además usan todos los niveles de un factor (Ejemplo genero)

* Aleatorias 

    + Se espera que su influencia sea impredecible e idiosincratica. Además no se usan todos los niveles de un factor (todos los individuos) A + Error(B)
    
## Ejemplo CO2

```{r, echo = FALSE}
data(CO2)
ggplot(CO2, aes(x = conc, y = uptake)) + geom_point(aes(shape = Treatment, fill = Type, color = Type)) + theme_classic()
```

## Ejemplo CO2

```{r, echo = FALSE}
kable(CO2, digits = 3) %>% kable_styling(bootstrap_options = c("striped", "hover")) %>% scroll_box(width = "100%", height = "400px")
```

## Modelos {.build}

```{r, echo = TRUE}
library(lme4)
mod1 <- lm(uptake ~ Type*Treatment + I(log(conc)) + conc, data = CO2)
mod2 <- lmer(uptake ~ Type*Treatment + I(log(conc)) + conc + (1|Plant), data = CO2)
```


```{r, echo=TRUE}
options(na.action = "na.fail")

Max.Vars <- floor(nrow(CO2)/10)

Seleccion <- dredge(mod2, m.lim = c(0, Max.Vars))
```

## Selección {.build}

```{r, echo = FALSE}
DF <- as.data.frame(Seleccion) %>%  mutate(weight = as.numeric(weight)) %>% mutate_if(is.factor, as.character)

kable(DF, digits = 3) %>% kable_styling(bootstrap_options = c("striped", "hover"), full_width = F, font_size = 16) %>% scroll_box(width = "100%", height = "300px")
```

* Solo el primer modelo es seleccionado

## Modelo

```{r, eval = FALSE}
BestModel <- get.models(Seleccion, 1)[[1]]
broom.mixed::tidy(BestModel)
```

```{r, echo=FALSE}
BestModel <- get.models(Seleccion, 1)[[1]]
DF <- broom.mixed::tidy(BestModel)

kable(DF, digits = 3) %>% kable_styling(bootstrap_options = c("striped", "hover"), full_width = F) %>% scroll_box(width = "100%", height = "300px")
```

## Modelo

```{r, echo = FALSE}
library(lme4)
NewData <- CO2

NewData$Pred <- predict(BestModel, re.form=NA, se.fit = T)
ggplot(NewData, aes(x = conc, y = Pred)) + geom_line(aes(color = Type, lty = Treatment)) + geom_point(aes(y = uptake, color = Type, shape = Treatment)) + theme_bw()
```


# Control mas detallado de dredge en MuMin


## Cemento

* ¿Que problema tiene la siguiente base de datos para LMs o GLMs?
* Ejemplo base de datos `Cement` de MuMIn

```{r, echo=FALSE}
library(MuMIn)
data("Cement")

Cement2 <- Cement %>% rename(Calorias  = y, CaAl = X1, SiCa3 = X2, Ca2AlFe = X3, Ca2Si = X4)

panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}

panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- cor(x, y)
  txt <- format(c(r, 0.123456789), digits = digits)[1]
  txt <- paste0(prefix, txt)
  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
  text(0.5, 0.5, txt, cex = cex.cor * abs(r))
}

pairs(Cement2, lower.panel = panel.smooth, upper.panel = panel.cor, diag.panel = panel.hist)


```

## Como agrego eso a MuMIn

```{r, echo=TRUE}
GlobalMod <- lm(Calorias ~., data = Cement2)
```


```{r, echo=TRUE, eval=FALSE}
cor(Cement2[,-1])
```

```{r, echo=FALSE}
kable(cor(Cement2[,-1])) %>% kable_styling(bootstrap_options = c("striped", "hover"), font_size = 20)
```


## Como agrego eso a MuMIn (cont)

```{r, echo=TRUE}
nm <- colnames(Cement2[-1])
smat <- abs(cor(Cement2[, -1])) <= .7
smat[!lower.tri(smat)] <- NA
```

```{r, echo=FALSE}
kable(smat) %>% kable_styling(bootstrap_options = c("striped", "hover"), font_size = 20)
```

## Como agrego eso a MuMIn (cont)

```{r, echo=TRUE}
options(na.action = "na.fail")
Selected <- dredge(GlobalMod, subset = smat)
```

```{r, echo=FALSE}
Selected <- Selected %>% mutate(weight = as.numeric(weight))
kable(Selected, digits = 2) %>% kable_styling(bootstrap_options = c("striped", "hover"), font_size = 20, full_width = F) %>% scroll_box(width = "100%", height = "400px")
```

## Incluir además límite de numero de variables

```{r, echo=TRUE}
options(na.action = "na.fail")
Selected <- dredge(GlobalMod, subset = smat, m.lim = c(0, floor(nrow(Cement)/10)))
```

```{r, echo=FALSE}
Selected <- Selected %>% mutate(weight = as.numeric(weight))
kable(Selected, digits = 2) %>% kable_styling(bootstrap_options = c("striped", "hover"), font_size = 20, full_width = F) %>% scroll_box(width = "100%", height = "400px")
```



```{r, echo=FALSE}
#sjPlot::plot_model(logitmod, type = "eff", terms = c("temp")) + ggtitle("") + ylab("Probabilidad de fallo") + xlab("Temp F") + theme_classic()
```

# Crossvalidation

## A veces no se pueden usar criterios de información {.build}

* No se pueden calcular IC
* No se cumplen supuestos de criterios de información
* Comparacion entre distintos tipos de modelos (GLM, vs GAM vs RPART, etc)
* Se aplican distintas transformaciones a la variable respuesta (GLM)
* Varios terminos polinomiales (no se debe promediar modelos)


## Alternativas a los métodos de criterios de información

* Simular que presentamos datos nuevos
  + Crossvalidation
  + Bootstrapping
  + Leave one out

```{r, echo=FALSE}
knitr::include_graphics("K-fold_cross_validation_EN.jpg", dpi = 70)
```


## k-fold Crossvalidation

* Divido aleatoreamente mi base de datos en $k$ grupos
* Entreno mis modelos con $k-1$ grupos 
* Testeo con el grupo $k_i$
* Promedio medida de desempeño por ejemplo $R^2$

## Volvamos al ejemplo de hp {.build}

```{r, echo = FALSE}
data(mtcars)
ggplot(mtcars, aes(x = hp, y = mpg)) + geom_smooth(method = "lm", lty = 2, color = "red") + geom_point() + theme_classic()
```

* Veamos como evaluamos 1 modelo $mpg = \beta_1 hp +c$
* $R^2$ = `r round(broom::glance(lm(mpg~hp, data = mtcars))$r.squared,2)`

 Paso 1 K-fold

## Divido my base en K  {.build}

* En este caso K = 5
    + Dividiremos nuestra base de datos en 5 partes iguales

```{r, echo = FALSE}
set.seed(2020)
Folds <- createFolds(mtcars$hp, 5)
Rs <- vector()

COLS <- rainbow(n = 5)
#data("diamonds")  
flds <- createFolds(mtcars$hp, k = 5, returnTrain = FALSE)
FOLDS <- list()
for(i in 1:5){
  FOLDS[[i]] <- mtcars[flds[[i]],]
  FOLDS[[i]]$Fold <- names(flds)[[i]]
  FOLDS[[i]]$Color <- COLS[i]
}

FOLDS <- bind_rows(FOLDS)

ggplot(FOLDS, aes(x = hp, y = mpg)) + geom_point(aes(color = Fold), alpha = 0.5) + theme_classic() + scale_color_manual(values =  COLS)

```

# Paso 2 Entreno y testeo para cada K

## Fold 1

```{r, echo=FALSE}
  temp <- COLS
  temp[!str_detect(temp, pattern = COLS[1])] <- "black"
  Train <- filter(FOLDS, Fold != unique(Fold)[1])
  Test <- filter(FOLDS, Fold == unique(Fold)[1])
  mod <- lm(mpg ~ hp, data = Train)
  Test$pred <- predict(mod, Test)
  Test$Rsq <- round(postResample(pred = Test$pred, obs = Test$mpg)[2],2)
  print(ggplot(Train, aes(x = hp, y = mpg)) + geom_point(color = "black", alpha = 0.5) + geom_point(data = Test, color = COLS[1]) + geom_line(data = Test, aes(x = hp, y = pred), lty = 2, color = "red") + geom_text(data = Test, x = 250, y = 30, aes(label =paste("Rsq =", Rsq))) + theme_classic() + theme(legend.position = "none") + ylim(c(3, 35))+ xlim(c(45,345))) 
  
  Rs[1] <- Test$Rsq
```

* Rsq = `r Rs`

## Fold 2

```{r, echo=FALSE}
  temp <- COLS
  temp[!str_detect(temp, pattern = COLS[2])] <- "black"
  Train <- filter(FOLDS, Fold != unique(Fold)[2])
  Test <- filter(FOLDS, Fold == unique(Fold)[2])
  mod <- lm(mpg ~ hp, data = Train)
  Test$pred <- predict(mod, Test)
  Test$Rsq <- round(postResample(pred = Test$pred, obs = Test$mpg)[2],2)
  
  Rs[2] <- Test$Rsq
  
  print(ggplot(Train, aes(x = hp, y = mpg)) + geom_point(color = "black", alpha = 0.5) + geom_point(data = Test, color = COLS[2]) + geom_line(data = Test, aes(x = hp, y = pred), lty = 2, color = COLS[2]) + geom_text(data = Test, x = 250, y = 30, aes(label =paste("Rsq =", Rsq))) + theme_classic() + theme(legend.position = "none") + ylim(c(3, 35))+ xlim(c(45,345))) 
  
```

* Rsq = `r Rs`

## Fold 3

```{r, echo=FALSE}
  temp <- COLS
  temp[!str_detect(temp, pattern = COLS[3])] <- "black"
  Train <- filter(FOLDS, Fold != unique(Fold)[3])
  Test <- filter(FOLDS, Fold == unique(Fold)[3])
  mod <- lm(mpg ~ hp, data = Train)
  Test$pred <- predict(mod, Test)
  Test$Rsq <- round(postResample(pred = Test$pred, obs = Test$mpg)[2],2)
  Rs[3] <- Test$Rsq
  print(ggplot(Train, aes(x = hp, y = mpg)) + geom_point(color = "black", alpha = 0.5) + geom_point(data = Test, color = COLS[3]) + geom_line(data = Test, aes(x = hp, y = pred), lty = 2, color = COLS[3]) + geom_text(data = Test, x = 250, y = 30, aes(label =paste("Rsq =", Rsq))) + theme_classic() + theme(legend.position = "none") + ylim(c(3, 35))+ xlim(c(45,345))) 
```

* Rsq = `r Rs`

## Fold 4

```{r, echo=FALSE}
  temp <- COLS
  temp[!str_detect(temp, pattern = COLS[4])] <- "black"
  Train <- filter(FOLDS, Fold != unique(Fold)[4])
  Test <- filter(FOLDS, Fold == unique(Fold)[4])
  mod <- lm(mpg ~ hp, data = Train)
  Test$pred <- predict(mod, Test)
  Test$Rsq <- round(postResample(pred = Test$pred, obs = Test$mpg)[2],2)
  Rs[4] <- Test$Rsq
  print(ggplot(Train, aes(x = hp, y = mpg)) + geom_point(color = "black", alpha = 0.5) + geom_point(data = Test, color = COLS[4]) + geom_line(data = Test, aes(x = hp, y = pred), lty = 2, color = COLS[4]) + geom_text(data = Test, x = 250, y = 30, aes(label =paste("Rsq =", Rsq))) + theme_classic() + theme(legend.position = "none") + ylim(c(3, 35))+ xlim(c(45,345))) 
```

* Rsq = `r Rs`

## Fold 5 {.build}

```{r, echo=FALSE}
  temp <- COLS
  temp[!str_detect(temp, pattern = COLS[5])] <- "black"
  Train <- filter(FOLDS, Fold != unique(Fold)[5])
  Test <- filter(FOLDS, Fold == unique(Fold)[5])
  mod <- lm(mpg ~ hp, data = Train)
  Test$pred <- predict(mod, Test)
  
  Test$Rsq <- round(postResample(pred = Test$pred, obs = Test$mpg)[2],2)
  
  Rs[5] <- Test$Rsq
  
  print(ggplot(Train, aes(x = hp, y = mpg)) + geom_point(color = "black", alpha = 0.5) + geom_point(data = Test, color = COLS[5]) + geom_line(data = Test, aes(x = hp, y = pred), lty = 2, color = COLS[5]) + geom_text(data = Test, x = 250, y = 30, aes(label =paste("Rsq =", Rsq))) + theme_classic() + theme(legend.position = "none") + ylim(c(3, 35))+ xlim(c(45,345))) 
```

* Rsq = `r Rs`
* Rsq = `r mean(Rs)`

# Con Caret

## CV en caret {.build .small}

* para 1 modelo

```{r, echo = TRUE}
set.seed(2020)
ctrl <- trainControl(method = "cv",number = 5)

Modelo <- train(mpg ~ hp, data = mtcars, method = "lm",trControl = ctrl)

DF <- Modelo$resample 

DF <- DF %>% select(Rsquared,Resample)
```

## Continuado {.small .build}

```{r, echo=FALSE}
kable(DF, digits = 3) %>% kable_styling(bootstrap_options = c("striped", "hover"))
```


## Seleccionando por crossvalidation {.build .small}

```{r, echo = TRUE}
form1 <- "mpg ~ hp"
form2 <- "mpg ~ hp + I(hp^2)"
form3 <- "mpg ~ hp + I(hp^2) + I(hp^3)"
form4 <- "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4)"
form5 <- "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5)"
form6 <- "mpg ~ hp + I(hp^2) + I(hp^3) + I(hp^4) + I(hp^5) + I(hp^6)"

forms <- list(form1, form2, form3, form4, form5, form6)
K = (2:7)

ctrl <- trainControl(method = "cv",number = 5)
```

## Continuado {.small .build}

```{r, echo = TRUE, tidy.opts= list(blank = FALSE, width.cutoff = 30)}
set.seed(2020)
Tests <- forms %>% map(~train(as.formula(.x), data = mtcars, method = "lm",trControl = ctrl)) %>% map(~as.data.frame(.x$resample)) %>% map(~select(.x, Rsquared))  %>% map(~summarise_all(.x,funs(mean, sd), na.rm = T)) %>% map2(.y = forms,~ mutate(.x, model = .y)) %>% reduce(bind_rows) %>% mutate(K = K) %>% arrange(desc(mean))
```

## Continuado {.small .build}

```{r, echo=FALSE}
kable(Tests, digits = 3) %>% kable_styling(bootstrap_options = c("striped", "hover"))
```


# 

# Entender la hipótesis estadística a generar basado en la hipótesis biológica

## Pregunta 1 {.build}

* ¿Cual de estas relaciones es la que uno esperaría ver al finalizar el experimento?


```{r, echo=FALSE, fig.height= 4}
Fit1 <- glm(weight ~ Time + Diet:Time, family = poisson, data = ChickWeight)
  
Fit2 <- glm(weight ~ Time + Diet, family = poisson, data = ChickWeight)
  
Fit3 <- glm(weight ~ Time*Diet, family = poisson, data = ChickWeight)

DATA <- ChickWeight
DATA1 <- ChickWeight
DATA2 <- ChickWeight
DATA3 <- ChickWeight


DATA1$Pred <- predict(Fit1, newdata = DATA, type = "response")
DATA1$sd <- predict(Fit1, newdata = DATA, type = "response", se.fit = T)$se.fit
DATA1$Model <- "A"

DATA2$Pred <- predict(Fit2, newdata = DATA, type = "response")
DATA2$sd <- predict(Fit2, newdata = DATA, type = "response", se.fit = T)$se.fit
DATA2$Model <- "B"

DATA3$Pred <- predict(Fit3, newdata = DATA, type = "response")
DATA3$sd <- predict(Fit3, newdata = DATA, type = "response", se.fit = T)$se.fit
DATA3$Model <- "C"

DATA <- list(DATA1, DATA2, DATA3) %>% reduce(bind_rows)

ggplot(DATA, aes(x = Time, y = Pred, color = Diet)) + geom_ribbon(aes(ymax = Pred + sd, ymin = Pred - sd, fill = Diet), alpha = 0.5) + geom_line(aes(color = Diet)) + facet_grid(.~ Model) + theme_bw()

library(countdown)
library(beepr)
```


* Respuesta: A

## Pregunta 2

* ¿Cuál de estos códigos resultaría en el modelo que generaría este gráfico?

```{r, echo=FALSE, fig.height= 3}
ggplot(DATA1, aes(x = Time, y = Pred, color = Diet)) + geom_ribbon(aes(ymax = Pred + sd, ymin = Pred - sd, fill = Diet), alpha = 0.5) + geom_line(aes(color = Diet)) + theme_bw()
```

```{r, eval = F}
A <- glm(weight ~ Time + Diet, family = poisson)
B <- glm(weight ~ Time*Diet, family = poisson)
C <- glm(weight ~ Time + Time:Diet, family = poisson)
```



## Pregunta 2 (cont){.small}

```{r, tidy.opts= list(blank = FALSE, width.cutoff = 60)}
library(lme4)
ChickPoissMM1 <- glmer(weight ~ Time + Diet + (1|Chick), family = poisson, data = ChickWeight)

ChickPoissMM2 <- glmer(weight ~ Time + Time:Diet + (1|Chick), family = poisson, data = ChickWeight)

ChickPoissMM3 <- glmer(weight ~ Time + Time*Diet + (1|Chick), family = poisson, data = ChickWeight)
```

## Pregunta 3

* ¿Cuanto pesaria un pollo en el dia 10 en la dieta 2 basado en el modelo anterior?

```{r, echo=F}
kable(broom.mixed::tidy(ChickPoissMM2), digits = 2) %>% kable_styling(bootstrap_options = c("striped", "hover"), font_size = 20, full_width = F)
```

* A = `r exp(3.83 + 10*0.07 + 0.02)`
* B = `r exp(3.83 + 10*0.07 + (10*0.02))`
* C = `r 3.83 + 10*0.07 + (10*0.02)`

## Pregunta 3 (cont)

```{r}
exp(3.83 + 10*0.07 + 0.02)

exp(3.83 + 10*0.07 + (10*0.02))

3.83 + 10*0.07 + (10*0.02)
```


## Pregunta 4

* ¿Cuál es el código que mejor representa este gráfico?


```{r, echo=FALSE, fig.height= 3}
ggplot(DATA2, aes(x = Time, y = Pred, color = Diet)) + geom_ribbon(aes(ymax = Pred + sd, ymin = Pred - sd, fill = Diet), alpha = 0.5) + geom_line(aes(color = Diet)) + theme_bw()
```

```{r, eval = F}
A <- glm(weight ~ Time + Diet, family = poisson)
B <- glm(weight ~ Time*Diet, family = poisson)
C <- glm(weight ~ Time + Time:Diet, family = poisson)
```


## Pregunta 5

* ¿Cuantas pendientes e interceptos espero ver en este modelo?

```{r, echo=FALSE, fig.height= 3}
ggplot(DATA2, aes(x = Time, y = Pred, color = Diet)) + geom_ribbon(aes(ymax = Pred + sd, ymin = Pred - sd, fill = Diet), alpha = 0.5) + geom_line(aes(color = Diet)) + theme_bw()
```


## Pregunta 5 (cont)

```{r, echo = F}
kable(tidy(Fit2), digits = 2) %>% kable_styling(bootstrap_options = c("striped", "hover"), font_size = 20, full_width = F)
```

# Dudas
